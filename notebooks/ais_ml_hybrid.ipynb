{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce003812",
   "metadata": {},
   "source": [
    "## ðŸ§  Fake News using Artificial Immune Systems \n",
    "\n",
    "In this notebook we evaluate the performance across:\n",
    "\n",
    "- AIS-only\n",
    "\n",
    "- Supervised Logistic Regression\n",
    "\n",
    "- A Hybrid Ensemble using a weighted combination of AIS and ML scores\n",
    "\n",
    "- Conduct 5-fold cross-validation to ensure robust and generalizable results\n",
    "\n",
    "\n",
    "\n",
    "### ðŸ“š [References](https://github.com/KaiDMML/FakeNewsNet)\n",
    "\n",
    "- Shu, K., Mahudeswaran, D., Wang, S., Lee, D., & Liu, H. (2018). **FakeNewsNet: A Data Repository with News Content, Social Context and Dynamic Information for Studying Fake News on Social Media.** *arXiv preprint arXiv:1809.01286*. [arXiv link](https://arxiv.org/abs/1809.01286)\n",
    "\n",
    "- Shu, K., Sliva, A., Wang, S., Tang, J., & Liu, H. (2017). **Fake News Detection on Social Media: A Data Mining Perspective.** *ACM SIGKDD Explorations Newsletter*, 19(1), 22â€“36. [DOI](https://doi.org/10.1145/3137597.3137600)\n",
    "\n",
    "- Shu, K., Wang, S., & Liu, H. (2017). **Exploiting Tri-Relationship for Fake News Detection.** *arXiv preprint arXiv:1712.07709*. [arXiv link](https://arxiv.org/abs/1712.07709)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f323bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "026fc813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real news shape: (624, 4)\n",
      "Fake news shape: (432, 4)\n",
      "\n",
      "Sample real news article:\n",
      "id                                             politifact14984\n",
      "news_url                             http://www.nfib-sbet.org/\n",
      "title              National Federation of Independent Business\n",
      "tweet_ids    967132259869487105\\t967164368768196609\\t967215...\n",
      "Name: 0, dtype: object\n",
      "\n",
      "Sample fake news article:\n",
      "id                                             politifact15014\n",
      "news_url             speedtalk.com/forum/viewtopic.php?t=51650\n",
      "title        BREAKING: First NFL Team Declares Bankruptcy O...\n",
      "tweet_ids    937349434668498944\\t937379378006282240\\t937380...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load real and fake from politifact\n",
    "basepath = \"/Users/ayeshamendoza/repos/fake-news-immune-system\"\n",
    "datapath = os.path.join(basepath, \"data/raw\")\n",
    "real = pd.read_csv(os.path.join(datapath, 'politifact_real.csv'))\n",
    "fake = pd.read_csv(os.path.join(datapath, 'politifact_fake.csv'))\n",
    "\n",
    "print(\"Real news shape:\", real.shape)\n",
    "print(\"Fake news shape:\", fake.shape)\n",
    "\n",
    "print(\"\\nSample real news article:\")\n",
    "print(real.iloc[0])\n",
    "\n",
    "print(\"\\nSample fake news article:\")\n",
    "print(fake.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843e4e8f",
   "metadata": {},
   "source": [
    "Data Preprocessing\n",
    "\n",
    "In order to be able to use the text data in our Deep Learning models, we will need to convert the text data to numbers.  In order to do that the following pre-processing steps were done:\n",
    "\n",
    "- Tokenization\n",
    "- Stemming\n",
    "- removing stopwords\n",
    "- removing punctuations\n",
    "- TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c22b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Download NLTK resources if not done\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# Define cleaning function\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb866da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    stop_words = ENGLISH_STOP_WORDS\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\.{2,}', ' ', text)              # remove ellipsis\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text) # remove URLs\n",
    "    text = re.sub(r'\\$\\w*', '', text)                # remove $ mentions\n",
    "    text = re.sub(r'#', '', text)                    # remove hashtags\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text)  # <-- remove punctuation\n",
    "\n",
    "    tokens = text.split()  # now safe to split on whitespace\n",
    "\n",
    "    cleaned_tokens = [\n",
    "        stemmer.stem(token)\n",
    "        for token in tokens\n",
    "        if token not in stop_words\n",
    "    ]\n",
    "\n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "basepath = \"/Users/ayeshamendoza/repos/fake-news-immune-system\"\n",
    "datapath = os.path.join(basepath, \"data/raw\")\n",
    "real = pd.read_csv(os.path.join(datapath, 'politifact_real.csv'))\n",
    "fake = pd.read_csv(os.path.join(datapath, 'politifact_fake.csv'))\n",
    "\n",
    "# Add label columns\n",
    "real['label'] = 'REAL'\n",
    "fake['label'] = 'FAKE'\n",
    "\n",
    "# Combine datasets\n",
    "df = pd.concat([real, fake], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33884fd3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61db820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                         clean_text\n",
      "0  REAL                         nation feder independ busi\n",
      "1  REAL                              comment fayettevil nc\n",
      "2  REAL  romney make pitch hope close deal elect rocki ...\n",
      "3  REAL  democrat leader say hous democrat unit gop def...\n",
      "4  REAL                   budget unit state govern fy 2008\n"
     ]
    }
   ],
   "source": [
    "# Apply cleaning\n",
    "df['clean_text'] = df['title'].fillna('')\n",
    "df['clean_text'] = df['clean_text'].apply(clean_text)\n",
    "\n",
    "\n",
    "# Save cleaned dataset\n",
    "df.to_csv('../data/processed/cleaned_articles.csv', index=False)\n",
    "\n",
    "# Preview cleaned text\n",
    "print(df[['label', 'clean_text']].head())\n",
    "\n",
    "article_texts = df['clean_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3064b6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (1056, 300)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "article_vectors = []\n",
    "for doc in nlp.pipe(article_texts, disable=[\"ner\", \"parser\"]):\n",
    "    article_vectors.append(doc.vector)\n",
    "\n",
    "article_vectors = np.array(article_vectors)\n",
    "print(\"Embeddings shape:\", article_vectors.shape)\n",
    "\n",
    "label_map = {'REAL': 0, 'FAKE': 1}\n",
    "true_labels = df['label'].map(label_map).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50192e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(article_vectors)\n",
    "y = np.array(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "339713b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') \n",
    "\n",
    "import src.negative_selection\n",
    "import importlib\n",
    "importlib.reload(src.negative_selection)\n",
    "\n",
    "from src.negative_selection import detect_anomaly, generate_detectors\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f7f109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PARAMETERS ===\n",
    "threshold = 0.45\n",
    "ml_weight = 0.7\n",
    "ais_weight = 1 - ml_weight\n",
    "n_splits = 5\n",
    "detector_params = {\n",
    "    \"num_detectors\": 500,\n",
    "    \"noise_std\": 0.07\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b03f0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 500 detectors in 6477 attempts (threshold=0.45, noise_std=0.07)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayeshamendoza/Library/Caches/pypoetry/virtualenvs/fake-news-immune-system-pOZ85LOU-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ayeshamendoza/Library/Caches/pypoetry/virtualenvs/fake-news-immune-system-pOZ85LOU-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ayeshamendoza/Library/Caches/pypoetry/virtualenvs/fake-news-immune-system-pOZ85LOU-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 500 detectors in 6540 attempts (threshold=0.45, noise_std=0.07)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayeshamendoza/Library/Caches/pypoetry/virtualenvs/fake-news-immune-system-pOZ85LOU-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ayeshamendoza/Library/Caches/pypoetry/virtualenvs/fake-news-immune-system-pOZ85LOU-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ayeshamendoza/Library/Caches/pypoetry/virtualenvs/fake-news-immune-system-pOZ85LOU-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 500 detectors in 7268 attempts (threshold=0.45, noise_std=0.07)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayeshamendoza/Library/Caches/pypoetry/virtualenvs/fake-news-immune-system-pOZ85LOU-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ayeshamendoza/Library/Caches/pypoetry/virtualenvs/fake-news-immune-system-pOZ85LOU-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ayeshamendoza/Library/Caches/pypoetry/virtualenvs/fake-news-immune-system-pOZ85LOU-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 500 detectors in 5939 attempts (threshold=0.45, noise_std=0.07)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayeshamendoza/Library/Caches/pypoetry/virtualenvs/fake-news-immune-system-pOZ85LOU-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ayeshamendoza/Library/Caches/pypoetry/virtualenvs/fake-news-immune-system-pOZ85LOU-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ayeshamendoza/Library/Caches/pypoetry/virtualenvs/fake-news-immune-system-pOZ85LOU-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 500 detectors in 7215 attempts (threshold=0.45, noise_std=0.07)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayeshamendoza/Library/Caches/pypoetry/virtualenvs/fake-news-immune-system-pOZ85LOU-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ayeshamendoza/Library/Caches/pypoetry/virtualenvs/fake-news-immune-system-pOZ85LOU-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ayeshamendoza/Library/Caches/pypoetry/virtualenvs/fake-news-immune-system-pOZ85LOU-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Perform Cross-validation\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "results_cv = {\"AIS\": [], \"ML\": [], \"Hybrid\": []}\n",
    "\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # AIS\n",
    "    X_train_real = X_train[y_train == 0]\n",
    "    detectors = generate_detectors(\n",
    "        num_detectors=detector_params[\"num_detectors\"],\n",
    "        vector_dim=X.shape[1],\n",
    "        self_matrix=X_train_real,\n",
    "        threshold=threshold,\n",
    "        noise_std=detector_params[\"noise_std\"]\n",
    "    )\n",
    "    ais_preds = [1 if detect_anomaly(vec, detectors, threshold, debug=False) else 0 for vec in X_test]\n",
    "\n",
    "    # ML\n",
    "    clf = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    ml_probs = clf.predict_proba(X_test)[:, 1]\n",
    "    ml_preds = (ml_probs >= threshold).astype(int)\n",
    "\n",
    "    # Hybrid\n",
    "    hybrid_scores = ais_weight * np.array(ais_preds) + ml_weight * ml_probs\n",
    "    hybrid_preds = (hybrid_scores >= threshold).astype(int)\n",
    "\n",
    "    # Store results\n",
    "    results_cv[\"AIS\"].append(classification_report(y_test, ais_preds, output_dict=True))\n",
    "    results_cv[\"ML\"].append(classification_report(y_test, ml_preds, output_dict=True))\n",
    "    results_cv[\"Hybrid\"].append(classification_report(y_test, hybrid_preds, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7084b852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Fake Precision  Fake Recall   Fake F1  Accuracy   Model\n",
      "0        0.000000     0.000000  0.000000  0.590910     AIS\n",
      "1        0.721166     0.844935  0.777726  0.802110      ML\n",
      "2        0.761255     0.664207  0.708928  0.777479  Hybrid\n"
     ]
    }
   ],
   "source": [
    "# Summarize and Compare results\n",
    "def summarize(results, label=\"1\"):\n",
    "    return {\n",
    "        \"Fake Precision\": np.mean([fold[label][\"precision\"] for fold in results]),\n",
    "        \"Fake Recall\":    np.mean([fold[label][\"recall\"] for fold in results]),\n",
    "        \"Fake F1\":        np.mean([fold[label][\"f1-score\"] for fold in results]),\n",
    "        \"Accuracy\":       np.mean([fold[\"accuracy\"] for fold in results])\n",
    "    }\n",
    "\n",
    "summary_data = []\n",
    "for model in [\"AIS\", \"ML\", \"Hybrid\"]:\n",
    "    metrics = summarize(results_cv[model])\n",
    "    metrics[\"Model\"] = model\n",
    "    summary_data.append(metrics)\n",
    "\n",
    "cv_df = pd.DataFrame(summary_data)\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0108bae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake-news-immune-system-pOZ85LOU-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
